{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network with Tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set/',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set/',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[32, 32, 3]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=12, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=12, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating the CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.6935 - accuracy: 0.5099 - val_loss: 0.6886 - val_accuracy: 0.5555\n",
      "Epoch 2/36\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.6860 - accuracy: 0.5490 - val_loss: 0.6823 - val_accuracy: 0.6030\n",
      "Epoch 3/36\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.6613 - accuracy: 0.6062 - val_loss: 0.6347 - val_accuracy: 0.6550\n",
      "Epoch 4/36\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.6319 - accuracy: 0.6464 - val_loss: 0.6176 - val_accuracy: 0.6680\n",
      "Epoch 5/36\n",
      "250/250 [==============================] - 24s 94ms/step - loss: 0.6163 - accuracy: 0.6670 - val_loss: 0.5882 - val_accuracy: 0.6970\n",
      "Epoch 6/36\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.5836 - accuracy: 0.6973 - val_loss: 0.6265 - val_accuracy: 0.6650\n",
      "Epoch 7/36\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.5722 - accuracy: 0.7016 - val_loss: 0.6139 - val_accuracy: 0.6890\n",
      "Epoch 8/36\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.5529 - accuracy: 0.7197 - val_loss: 0.5406 - val_accuracy: 0.7355\n",
      "Epoch 9/36\n",
      "250/250 [==============================] - 18s 70ms/step - loss: 0.5402 - accuracy: 0.7297 - val_loss: 0.6320 - val_accuracy: 0.6590\n",
      "Epoch 10/36\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.5262 - accuracy: 0.7372 - val_loss: 0.5053 - val_accuracy: 0.7645\n",
      "Epoch 11/36\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.5191 - accuracy: 0.7440 - val_loss: 0.5119 - val_accuracy: 0.7520\n",
      "Epoch 12/36\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.5068 - accuracy: 0.7524 - val_loss: 0.5026 - val_accuracy: 0.7560\n",
      "Epoch 13/36\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.5011 - accuracy: 0.7570 - val_loss: 0.5046 - val_accuracy: 0.7570\n",
      "Epoch 14/36\n",
      "250/250 [==============================] - 22s 87ms/step - loss: 0.4955 - accuracy: 0.7617 - val_loss: 0.5247 - val_accuracy: 0.7465\n",
      "Epoch 15/36\n",
      "250/250 [==============================] - 19s 76ms/step - loss: 0.4896 - accuracy: 0.7675 - val_loss: 0.5084 - val_accuracy: 0.7630\n",
      "Epoch 16/36\n",
      "250/250 [==============================] - 19s 78ms/step - loss: 0.4875 - accuracy: 0.7631 - val_loss: 0.4979 - val_accuracy: 0.7675\n",
      "Epoch 17/36\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4847 - accuracy: 0.7684 - val_loss: 0.5010 - val_accuracy: 0.7670\n",
      "Epoch 18/36\n",
      "250/250 [==============================] - 19s 76ms/step - loss: 0.4740 - accuracy: 0.7757 - val_loss: 0.5061 - val_accuracy: 0.7600\n",
      "Epoch 19/36\n",
      "250/250 [==============================] - 19s 78ms/step - loss: 0.4666 - accuracy: 0.7836 - val_loss: 0.4787 - val_accuracy: 0.7810\n",
      "Epoch 20/36\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.4713 - accuracy: 0.7772 - val_loss: 0.5325 - val_accuracy: 0.7360\n",
      "Epoch 21/36\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.4602 - accuracy: 0.7860 - val_loss: 0.4829 - val_accuracy: 0.7715\n",
      "Epoch 22/36\n",
      "250/250 [==============================] - 23s 93ms/step - loss: 0.4542 - accuracy: 0.7876 - val_loss: 0.5468 - val_accuracy: 0.7350\n",
      "Epoch 23/36\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.4554 - accuracy: 0.7857 - val_loss: 0.4837 - val_accuracy: 0.7725\n",
      "Epoch 24/36\n",
      "250/250 [==============================] - 19s 76ms/step - loss: 0.4412 - accuracy: 0.8005 - val_loss: 0.4848 - val_accuracy: 0.7785\n",
      "Epoch 25/36\n",
      "250/250 [==============================] - 22s 88ms/step - loss: 0.4515 - accuracy: 0.7930 - val_loss: 0.4906 - val_accuracy: 0.7645\n",
      "Epoch 26/36\n",
      "250/250 [==============================] - 26s 106ms/step - loss: 0.4429 - accuracy: 0.8001 - val_loss: 0.4909 - val_accuracy: 0.7780\n",
      "Epoch 27/36\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.4388 - accuracy: 0.8015 - val_loss: 0.4834 - val_accuracy: 0.7810\n",
      "Epoch 28/36\n",
      "250/250 [==============================] - 21s 85ms/step - loss: 0.4487 - accuracy: 0.7924 - val_loss: 0.4945 - val_accuracy: 0.7720\n",
      "Epoch 29/36\n",
      "250/250 [==============================] - 20s 78ms/step - loss: 0.4344 - accuracy: 0.8050 - val_loss: 0.5229 - val_accuracy: 0.7470\n",
      "Epoch 30/36\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.4301 - accuracy: 0.8062 - val_loss: 0.4775 - val_accuracy: 0.7815\n",
      "Epoch 31/36\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.4320 - accuracy: 0.8015 - val_loss: 0.5026 - val_accuracy: 0.7655\n",
      "Epoch 32/36\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.4210 - accuracy: 0.8100 - val_loss: 0.4813 - val_accuracy: 0.7745\n",
      "Epoch 33/36\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.4233 - accuracy: 0.8046 - val_loss: 0.5033 - val_accuracy: 0.7685\n",
      "Epoch 34/36\n",
      "250/250 [==============================] - 19s 75ms/step - loss: 0.4205 - accuracy: 0.8106 - val_loss: 0.5539 - val_accuracy: 0.7445\n",
      "Epoch 35/36\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.4134 - accuracy: 0.8165 - val_loss: 0.5178 - val_accuracy: 0.7580\n",
      "Epoch 36/36\n",
      "250/250 [==============================] - 18s 72ms/step - loss: 0.4125 - accuracy: 0.8146 - val_loss: 0.4884 - val_accuracy: 0.7805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa55c1f0040>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_set, validation_data=test_set, epochs=36)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating with single predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "test_image = tf.keras.utils.load_img('dataset/single_prediction/cat.jpg', target_size=(32, 32))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = model.predict(test_image)\n",
    "prediction = 'cat' if result < 0.5 else 'dog'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
